{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Navak94/deeplearning_HW4/blob/main/cnn_improved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fq5qQL6nN4f"
      },
      "source": [
        "If you decide to participate in the competition, save the **predictions.json and flops_and_params.json** files in a zip folder with your group name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "euVL16niu7I9"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j4LIaCuvJ-0",
        "outputId": "ef6007e4-2104-4964-9a65-4336a279dfaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FkwMavdnMjl"
      },
      "source": [
        "# Step 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRAmLlf5nMjl",
        "outputId": "2a0d2c01-cceb-48f0-e2f0-731aef2d2122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "betterCNN(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "import torch.nn as nn\n",
        "\n",
        "class betterCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(betterCNN, self).__init__()\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # pooling and dropout\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(256 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1 block\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 2 block\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 3 block\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # flatten\n",
        "        x = x.view(-1, 256 * 8 * 8)\n",
        "\n",
        "        # fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = betterCNN(num_classes=5)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjSPxfOnMjl"
      },
      "source": [
        "# Step 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PvU2Nqg5nMjm"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# transform with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# val transform (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset_dir = '/content/drive/MyDrive/train_set'\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=trainset_dir, transform=None)\n",
        "\n",
        "total_size = len(full_dataset)\n",
        "indices = list(range(total_size))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_size = int(0.85 * total_size)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "train_indices = indices[0:train_size]\n",
        "val_indices = indices[train_size:total_size]\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=trainset_dir, transform=train_transform)\n",
        "train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "\n",
        "val_dataset = datasets.ImageFolder(root=trainset_dir, transform=val_transform)\n",
        "val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrC8sgELnMjm"
      },
      "source": [
        "# Step 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "02ctrF30nMjm"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.09) # added label smoothing\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=0.00001) # added weight decay\n",
        "# added learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7eqAh_AnMjm"
      },
      "source": [
        "# Step 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFZZgKDAnMjm",
        "outputId": "f52dfed5-d9d2-4f67-8c4c-df7b95586050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " -> Train Loss: 5.0669, Train Acc: 28.71%\n",
            " -> Val Acc: 37.81%\n",
            "----> Best model saved ---> Val Acc: 37.81%\n",
            "\n",
            "Epoch 2/100\n",
            " -> Train Loss: 1.5103, Train Acc: 34.02%\n",
            " -> Val Acc: 40.26%\n",
            "----> Best model saved ---> Val Acc: 40.26%\n",
            "\n",
            "Epoch 3/100\n",
            " -> Train Loss: 1.5076, Train Acc: 34.93%\n",
            " -> Val Acc: 43.10%\n",
            "----> Best model saved ---> Val Acc: 43.10%\n",
            "\n",
            "Epoch 4/100\n",
            " -> Train Loss: 1.5053, Train Acc: 35.46%\n",
            " -> Val Acc: 43.29%\n",
            "----> Best model saved ---> Val Acc: 43.29%\n",
            "\n",
            "Epoch 5/100\n",
            " -> Train Loss: 1.4824, Train Acc: 37.87%\n",
            " -> Val Acc: 43.86%\n",
            "----> Best model saved ---> Val Acc: 43.86%\n",
            "\n",
            "Epoch 6/100\n",
            " -> Train Loss: 1.4767, Train Acc: 37.50%\n",
            " -> Val Acc: 47.26%\n",
            "----> Best model saved ---> Val Acc: 47.26%\n",
            "\n",
            "Epoch 7/100\n",
            " -> Train Loss: 1.4526, Train Acc: 39.81%\n",
            " -> Val Acc: 49.53%\n",
            "----> Best model saved ---> Val Acc: 49.53%\n",
            "\n",
            "Epoch 8/100\n",
            " -> Train Loss: 1.4357, Train Acc: 41.58%\n",
            " -> Val Acc: 45.94%\n",
            "\n",
            "Epoch 9/100\n",
            " -> Train Loss: 1.4142, Train Acc: 43.52%\n",
            " -> Val Acc: 45.75%\n",
            "\n",
            "Epoch 10/100\n",
            " -> Train Loss: 1.3895, Train Acc: 45.25%\n",
            " -> Val Acc: 50.47%\n",
            "----> Best model saved ---> Val Acc: 50.47%\n",
            "\n",
            "Epoch 11/100\n",
            " -> Train Loss: 1.3876, Train Acc: 45.29%\n",
            " -> Val Acc: 50.85%\n",
            "----> Best model saved ---> Val Acc: 50.85%\n",
            "\n",
            "Epoch 12/100\n",
            " -> Train Loss: 1.3812, Train Acc: 44.32%\n",
            " -> Val Acc: 52.55%\n",
            "----> Best model saved ---> Val Acc: 52.55%\n",
            "\n",
            "Epoch 13/100\n",
            " -> Train Loss: 1.3642, Train Acc: 45.96%\n",
            " -> Val Acc: 53.12%\n",
            "----> Best model saved ---> Val Acc: 53.12%\n",
            "\n",
            "Epoch 14/100\n",
            " -> Train Loss: 1.3554, Train Acc: 46.59%\n",
            " -> Val Acc: 52.17%\n",
            "\n",
            "Epoch 15/100\n",
            " -> Train Loss: 1.3428, Train Acc: 47.69%\n",
            " -> Val Acc: 52.17%\n",
            "\n",
            "Epoch 16/100\n",
            " -> Train Loss: 1.3419, Train Acc: 47.43%\n",
            " -> Val Acc: 51.98%\n",
            "\n",
            "Epoch 17/100\n",
            " -> Train Loss: 1.3309, Train Acc: 48.73%\n",
            " -> Val Acc: 56.14%\n",
            "----> Best model saved ---> Val Acc: 56.14%\n",
            "\n",
            "Epoch 18/100\n",
            " -> Train Loss: 1.3131, Train Acc: 48.80%\n",
            " -> Val Acc: 55.58%\n",
            "\n",
            "Epoch 19/100\n",
            " -> Train Loss: 1.3060, Train Acc: 50.50%\n",
            " -> Val Acc: 54.44%\n",
            "\n",
            "Epoch 20/100\n",
            " -> Train Loss: 1.2992, Train Acc: 49.80%\n",
            " -> Val Acc: 55.58%\n",
            "\n",
            "Epoch 21/100\n",
            " -> Train Loss: 1.2936, Train Acc: 50.74%\n",
            " -> Val Acc: 57.84%\n",
            "----> Best model saved ---> Val Acc: 57.84%\n",
            "\n",
            "Epoch 22/100\n",
            " -> Train Loss: 1.2772, Train Acc: 51.14%\n",
            " -> Val Acc: 58.60%\n",
            "----> Best model saved ---> Val Acc: 58.60%\n",
            "\n",
            "Epoch 23/100\n",
            " -> Train Loss: 1.2794, Train Acc: 50.10%\n",
            " -> Val Acc: 56.90%\n",
            "\n",
            "Epoch 24/100\n",
            " -> Train Loss: 1.2601, Train Acc: 52.37%\n",
            " -> Val Acc: 57.28%\n",
            "\n",
            "Epoch 25/100\n",
            " -> Train Loss: 1.2700, Train Acc: 52.54%\n",
            " -> Val Acc: 57.09%\n",
            "\n",
            "Epoch 26/100\n",
            " -> Train Loss: 1.2321, Train Acc: 53.18%\n",
            " -> Val Acc: 57.66%\n",
            "\n",
            "Epoch 27/100\n",
            " -> Train Loss: 1.2393, Train Acc: 52.71%\n",
            " -> Val Acc: 59.92%\n",
            "----> Best model saved ---> Val Acc: 59.92%\n",
            "\n",
            "Epoch 28/100\n",
            " -> Train Loss: 1.2355, Train Acc: 52.97%\n",
            " -> Val Acc: 57.66%\n",
            "\n",
            "Epoch 29/100\n",
            " -> Train Loss: 1.2214, Train Acc: 54.88%\n",
            " -> Val Acc: 59.36%\n",
            "\n",
            "Epoch 30/100\n",
            " -> Train Loss: 1.2312, Train Acc: 54.78%\n",
            " -> Val Acc: 60.68%\n",
            "----> Best model saved ---> Val Acc: 60.68%\n",
            "\n",
            "Epoch 31/100\n",
            " -> Train Loss: 1.2209, Train Acc: 54.88%\n",
            " -> Val Acc: 59.92%\n",
            "\n",
            "Epoch 32/100\n",
            " -> Train Loss: 1.2082, Train Acc: 55.28%\n",
            " -> Val Acc: 59.74%\n",
            "\n",
            "Epoch 33/100\n",
            " -> Train Loss: 1.2165, Train Acc: 55.38%\n",
            " -> Val Acc: 56.90%\n",
            "\n",
            "Epoch 34/100\n",
            " -> Train Loss: 1.2027, Train Acc: 55.41%\n",
            " -> Val Acc: 57.66%\n",
            "\n",
            "Epoch 35/100\n",
            " -> Train Loss: 1.2081, Train Acc: 55.05%\n",
            " -> Val Acc: 63.71%\n",
            "----> Best model saved ---> Val Acc: 63.71%\n",
            "\n",
            "Epoch 36/100\n",
            " -> Train Loss: 1.1841, Train Acc: 56.15%\n",
            " -> Val Acc: 61.63%\n",
            "\n",
            "Epoch 37/100\n",
            " -> Train Loss: 1.1651, Train Acc: 56.72%\n",
            " -> Val Acc: 61.81%\n",
            "\n",
            "Epoch 38/100\n",
            " -> Train Loss: 1.1844, Train Acc: 55.31%\n",
            " -> Val Acc: 58.79%\n",
            "\n",
            "Epoch 39/100\n",
            " -> Train Loss: 1.1864, Train Acc: 56.85%\n",
            " -> Val Acc: 64.46%\n",
            "----> Best model saved ---> Val Acc: 64.46%\n",
            "\n",
            "Epoch 40/100\n",
            " -> Train Loss: 1.1578, Train Acc: 58.05%\n",
            " -> Val Acc: 61.81%\n",
            "\n",
            "Epoch 41/100\n",
            " -> Train Loss: 1.1450, Train Acc: 59.39%\n",
            " -> Val Acc: 61.44%\n",
            "\n",
            "Epoch 42/100\n",
            " -> Train Loss: 1.1633, Train Acc: 57.52%\n",
            " -> Val Acc: 59.55%\n",
            "\n",
            "Epoch 43/100\n",
            " -> Train Loss: 1.1301, Train Acc: 60.49%\n",
            " -> Val Acc: 64.84%\n",
            "----> Best model saved ---> Val Acc: 64.84%\n",
            "\n",
            "Epoch 44/100\n",
            " -> Train Loss: 1.1471, Train Acc: 58.05%\n",
            " -> Val Acc: 60.11%\n",
            "\n",
            "Epoch 45/100\n",
            " -> Train Loss: 1.1327, Train Acc: 59.36%\n",
            " -> Val Acc: 62.57%\n",
            "\n",
            "Epoch 46/100\n",
            " -> Train Loss: 1.1129, Train Acc: 60.29%\n",
            " -> Val Acc: 64.46%\n",
            "\n",
            "Epoch 47/100\n",
            " -> Train Loss: 1.1121, Train Acc: 62.00%\n",
            " -> Val Acc: 65.03%\n",
            "----> Best model saved ---> Val Acc: 65.03%\n",
            "\n",
            "Epoch 48/100\n",
            " -> Train Loss: 1.1100, Train Acc: 61.56%\n",
            " -> Val Acc: 62.19%\n",
            "\n",
            "Epoch 49/100\n",
            " -> Train Loss: 1.1161, Train Acc: 60.76%\n",
            " -> Val Acc: 63.89%\n",
            "\n",
            "Epoch 50/100\n",
            " -> Train Loss: 1.1089, Train Acc: 61.80%\n",
            " -> Val Acc: 66.35%\n",
            "----> Best model saved ---> Val Acc: 66.35%\n",
            "\n",
            "Epoch 51/100\n",
            " -> Train Loss: 1.0907, Train Acc: 63.03%\n",
            " -> Val Acc: 67.30%\n",
            "----> Best model saved ---> Val Acc: 67.30%\n",
            "\n",
            "Epoch 52/100\n",
            " -> Train Loss: 1.0907, Train Acc: 61.80%\n",
            " -> Val Acc: 63.33%\n",
            "\n",
            "Epoch 53/100\n",
            " -> Train Loss: 1.0680, Train Acc: 63.50%\n",
            " -> Val Acc: 64.46%\n",
            "\n",
            "Epoch 54/100\n",
            " -> Train Loss: 1.0664, Train Acc: 64.07%\n",
            " -> Val Acc: 66.35%\n",
            "\n",
            "Epoch 55/100\n",
            " -> Train Loss: 1.0560, Train Acc: 64.27%\n",
            " -> Val Acc: 67.11%\n",
            "\n",
            "Epoch 56/100\n",
            " -> Train Loss: 1.0668, Train Acc: 62.87%\n",
            " -> Val Acc: 65.78%\n",
            "\n",
            "Epoch 57/100\n",
            " -> Train Loss: 1.0756, Train Acc: 63.37%\n",
            " -> Val Acc: 63.14%\n",
            "\n",
            "Epoch 58/100\n",
            " -> Train Loss: 1.0228, Train Acc: 67.05%\n",
            " -> Val Acc: 69.94%\n",
            "----> Best model saved ---> Val Acc: 69.94%\n",
            "\n",
            "Epoch 59/100\n",
            " -> Train Loss: 0.9883, Train Acc: 69.45%\n",
            " -> Val Acc: 66.35%\n",
            "\n",
            "Epoch 60/100\n",
            " -> Train Loss: 0.9983, Train Acc: 66.74%\n",
            " -> Val Acc: 66.92%\n",
            "\n",
            "Epoch 61/100\n",
            " -> Train Loss: 1.0002, Train Acc: 67.55%\n",
            " -> Val Acc: 68.24%\n",
            "\n",
            "Epoch 62/100\n",
            " -> Train Loss: 0.9860, Train Acc: 68.55%\n",
            " -> Val Acc: 69.19%\n",
            "\n",
            "Epoch 63/100\n",
            " -> Train Loss: 0.9882, Train Acc: 67.95%\n",
            " -> Val Acc: 69.57%\n",
            "\n",
            "Epoch 64/100\n",
            " -> Train Loss: 0.9823, Train Acc: 68.15%\n",
            " -> Val Acc: 67.86%\n",
            "\n",
            "Epoch 65/100\n",
            " -> Train Loss: 0.9413, Train Acc: 71.42%\n",
            " -> Val Acc: 69.38%\n",
            "\n",
            "Epoch 66/100\n",
            " -> Train Loss: 0.9443, Train Acc: 71.32%\n",
            " -> Val Acc: 69.75%\n",
            "\n",
            "Epoch 67/100\n",
            " -> Train Loss: 0.9268, Train Acc: 71.62%\n",
            " -> Val Acc: 68.62%\n",
            "\n",
            "Epoch 68/100\n",
            " -> Train Loss: 0.9125, Train Acc: 72.03%\n",
            " -> Val Acc: 69.38%\n"
          ]
        }
      ],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 10\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss = running_loss + loss.item()\n",
        "\n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            train_total = train_total + labels.size(0)\n",
        "            train_correct = train_correct + (predictions == labels).sum().item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # val\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                predictions = torch.max(outputs, 1)[1]\n",
        "                val_total = val_total + labels.size(0)\n",
        "                val_correct = val_correct + (predictions == labels).sum().item()\n",
        "\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(f\" -> Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\" -> Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # new scheduler step\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # save state added\n",
        "        if val_acc >= best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"----> Best model saved ---> Val Acc: {val_acc:.2f}%\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter = patience_counter + 1\n",
        "\n",
        "        # early stopping\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            break\n",
        "\n",
        "        print()\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "train_losses, val_accuracies = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    num_epochs=100\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_wEZfF1nMjn"
      },
      "source": [
        "# Step 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFYvvCAhnMjn",
        "outputId": "a63bb200-2f44-44f7-88f2-7750bb468fdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Accuracy: 69.94%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "69.94328922495274"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#| label: prob1\n",
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            total = total + labels.size(0)\n",
        "            correct = correct + (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    print(f'Val Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdi-7Yopl4dp"
      },
      "source": [
        "Please don't make any change after this line. The only parameters you may modify are those within the \"test_transform\" function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jdVw9_b0I1ab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def filename2index(self, filename):\n",
        "        return os.path.basename(filename).replace('.jpg', '')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.filename2index(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vxPmHc1OMa_8"
      },
      "outputs": [],
      "source": [
        "test_folder = '/content/drive/MyDrive/test_set'\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_dataset = CustomImageDataset(test_folder, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCDIWpGM0y-",
        "outputId": "dceb48ca-ee31-4cb1-ba98-f24a30b9712d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation completed and predictions saved.\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "def evaluate_model(model, test_loader, idx_to_class):\n",
        "    all_predictions = {}\n",
        "    with torch.no_grad():\n",
        "        for inputs, index in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_class = predicted.item()\n",
        "            predicted_class_name = idx_to_class[predicted_class]\n",
        "            all_predictions[index[0]] = predicted_class_name\n",
        "\n",
        "    return all_predictions\n",
        "\n",
        "predictions = evaluate_model(model, test_loader, idx_to_class)\n",
        "with open('predictions.json', 'w') as json_file:\n",
        "    json.dump(predictions, json_file, indent=4)\n",
        "\n",
        "print(\"Evaluation completed and predictions saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ym3lmK2Eh36",
        "outputId": "45409607-3e44-465a-9fb6-1f5ad787a7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# you may need to install thop when you first run this code\n",
        "!pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BecI85f3EYiA",
        "outputId": "23a4af8a-ae3c-49eb-87f4-0db09226d49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "FLOPs: 623118848.0\n",
            "Number of Parameters: 9538885.0\n",
            "FLOPs and parameters have been saved to flops_and_params.json\n"
          ]
        }
      ],
      "source": [
        "# Compute FLOPs using thop\n",
        "import thop\n",
        "input_tensor = test_dataset[0][0].unsqueeze(0).to(device) # must have exact same size of the data input (batch, channel, height, width) and be on the same device as the model\n",
        "flops, params = thop.profile(model, inputs=(input_tensor,))\n",
        "print(f\"FLOPs: {flops}\")\n",
        "print(f\"Number of Parameters: {params}\")\n",
        "flops_and_params = {\n",
        "    \"FLOPs\": flops,\n",
        "    \"Parameters\": params\n",
        "}\n",
        "\n",
        "output_json_path = 'flops_and_params.json'\n",
        "\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(flops_and_params, json_file, indent=4)\n",
        "\n",
        "print(f\"FLOPs and parameters have been saved to {output_json_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
