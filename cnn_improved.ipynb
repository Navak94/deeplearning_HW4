{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fq5qQL6nN4f"
      },
      "source": [
        "If you decide to participate in the competition, save the **predictions.json and flops_and_params.json** files in a zip folder with your group name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "euVL16niu7I9"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j4LIaCuvJ-0",
        "outputId": "815e9c9a-fb19-4007-d015-c77ef45ecb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FkwMavdnMjl"
      },
      "source": [
        "# Step 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRAmLlf5nMjl",
        "outputId": "1fa2927a-cb0c-4d4f-e6cc-35cc4e121bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "betterCNN(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "import torch.nn as nn\n",
        "\n",
        "class betterCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(betterCNN, self).__init__()\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # convolutional block\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # pooling and dropout\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1 block\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 2 block\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # 3 block\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # flatten\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "\n",
        "        # fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = betterCNN(num_classes=5)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjSPxfOnMjl"
      },
      "source": [
        "# Step 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvU2Nqg5nMjm"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# transform with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# val transform (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset_dir = '/content/drive/MyDrive/train_set'\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=trainset_dir, transform=None)\n",
        "\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "train_indices = list(range(0, train_size))\n",
        "val_indices = list(range(train_size, total_size))\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=trainset_dir, transform=train_transform)\n",
        "train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "\n",
        "val_dataset = datasets.ImageFolder(root=trainset_dir, transform=val_transform)\n",
        "val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrC8sgELnMjm"
      },
      "source": [
        "# Step 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vNJ-kQzPDL4a"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "02ctrF30nMjm"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # loss + add label smoothing\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001) # optimizer + add weight decay\n",
        "# added learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7eqAh_AnMjm"
      },
      "source": [
        "# Step 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFZZgKDAnMjm"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 10\n",
        "\n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # train\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss = running_loss + loss.item()\n",
        "\n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            train_total = train_total + labels.size(0)\n",
        "            train_correct = train_correct + (predictions == labels).sum().item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # val\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                predictions = torch.max(outputs, 1)[1]\n",
        "                val_total = val_total + labels.size(0)\n",
        "                val_correct = val_correct + (predictions == labels).sum().item()\n",
        "\n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(f\" -> Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\" -> Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # new scheduler step\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # save state added\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"----> Best model saved ---> Val Acc: {val_acc:.2f}%\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter = patience_counter + 1\n",
        "\n",
        "        # early stopping\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            break\n",
        "\n",
        "        print()\n",
        "\n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "train_losses, val_accuracies = train(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    num_epochs=30\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_wEZfF1nMjn"
      },
      "source": [
        "# Step 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFYvvCAhnMjn"
      },
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            total = total + labels.size(0)\n",
        "            correct = correct + (predictions == labels).sum().item()\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    print(f'Val Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdi-7Yopl4dp"
      },
      "source": [
        "Please don't make any change after this line. The only parameters you may modify are those within the \"test_transform\" function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdVw9_b0I1ab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def filename2index(self, filename):\n",
        "        return os.path.basename(filename).replace('.jpg', '')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.filename2index(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPmHc1OMa_8"
      },
      "outputs": [],
      "source": [
        "test_folder = '/content/drive/MyDrive/test_set'\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)), # same image size applied for validation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # same mean and std applied for validation\n",
        "])\n",
        "test_dataset = CustomImageDataset(test_folder, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jCDIWpGM0y-"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "def evaluate_model(model, test_loader, idx_to_class):\n",
        "    all_predictions = {}\n",
        "    with torch.no_grad():\n",
        "        for inputs, index in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_class = predicted.item()\n",
        "            predicted_class_name = idx_to_class[predicted_class]\n",
        "            all_predictions[index[0]] = predicted_class_name\n",
        "\n",
        "    return all_predictions\n",
        "\n",
        "predictions = evaluate_model(model, test_loader, idx_to_class)\n",
        "with open('predictions.json', 'w') as json_file:\n",
        "    json.dump(predictions, json_file, indent=4)\n",
        "\n",
        "print(\"Evaluation completed and predictions saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ym3lmK2Eh36"
      },
      "outputs": [],
      "source": [
        "# you may need to install thop when you first run this code\n",
        "# !pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BecI85f3EYiA"
      },
      "outputs": [],
      "source": [
        "# Compute FLOPs using thop\n",
        "import thop\n",
        "input_tensor = test_dataset[0][0].unsqueeze(0) # must have exact same size of the data input (batch, channel, height, width)\n",
        "flops, params = thop.profile(model, inputs=(input_tensor,))\n",
        "print(f\"FLOPs: {flops}\")\n",
        "print(f\"Number of Parameters: {params}\")\n",
        "flops_and_params = {\n",
        "    \"FLOPs\": flops,\n",
        "    \"Parameters\": params\n",
        "}\n",
        "\n",
        "output_json_path = 'flops_and_params.json'\n",
        "\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(flops_and_params, json_file, indent=4)\n",
        "\n",
        "print(f\"FLOPs and parameters have been saved to {output_json_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
