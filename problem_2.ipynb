{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f30bcfa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30bcfa9",
        "outputId": "c0f5c228-1b0b-4667-e55d-497f8e158413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "path = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2f1f70d6",
      "metadata": {
        "id": "2f1f70d6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "os.chdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "76f0ed51",
      "metadata": {
        "id": "76f0ed51"
      },
      "outputs": [],
      "source": [
        "# load training and test data\n",
        "def loadData():\n",
        "    X_train = np.load('X_train.npy',allow_pickle=True)\n",
        "    y_train = np.load('y_train.npy',allow_pickle=True)\n",
        "    X_test = np.load('X_test.npy',allow_pickle=True)\n",
        "    y_test = np.load('y_test.npy',allow_pickle=True)\n",
        "\n",
        "    X_train = [torch.Tensor(x) for x in X_train]  # List of Tensors (SEQ_LEN[i],INPUT_DIM) i=0..NUM_SAMPLES-1\n",
        "    X_test = [torch.Tensor(x) for x in X_test]  # List of Tensors (SEQ_LEN[i],INPUT_DIM)\n",
        "    y_train = torch.Tensor(y_train) # (NUM_SAMPLES,1)\n",
        "    y_test = torch.Tensor(y_test) # (NUM_SAMPLES,1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "21bb0ab1",
      "metadata": {
        "id": "21bb0ab1"
      },
      "outputs": [],
      "source": [
        "# Define a Vanilla RNN layer by hand\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.W_xh = nn.Parameter(torch.randn(input_size, hidden_size) * 0.01)\n",
        "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "        self.activation = torch.tanh\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        hidden = self.activation(x @ self.W_xh + hidden @ self.W_hh)\n",
        "        return hidden\n",
        "\n",
        "# Define a sequence prediction model using the Vanilla RNN\n",
        "class SequenceModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SequenceModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = RNNLayer(input_size, hidden_size)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq, seq_lengths):\n",
        "        batch_size = len(input_seq)\n",
        "        last_hidden = torch.zeros(batch_size, self.hidden_size, device=device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            hidden = torch.zeros(self.hidden_size, device=device)\n",
        "\n",
        "            seq_length =  seq_lengths[b]\n",
        "\n",
        "            for t in range(seq_length):\n",
        "                hidden = self.rnn(input_seq[b][t], hidden)\n",
        "\n",
        "            # Store the last hidden state in the output tensor\n",
        "            last_hidden[b] = hidden\n",
        "\n",
        "        output = self.linear(last_hidden)\n",
        "        return output\n",
        "\n",
        "# Define a sequence prediction model for fixed length sequences, BUT NO SHARED WEIGHTS\n",
        "class SequenceModelFixedLen(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, seq_len):\n",
        "        super(SequenceModelFixedLen, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.rnn_layers = nn.ModuleList([RNNLayer(input_size, hidden_size) for _ in range(seq_len)])\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq, seq_lengths):\n",
        "        batch_size = len(input_seq)\n",
        "        last_hidden = torch.zeros(batch_size, self.hidden_size, device=device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            hidden = torch.zeros(self.hidden_size, device=device).to(device)\n",
        "\n",
        "            seq_length = min(self.seq_len, seq_lengths[b])\n",
        "            for t in range(seq_length):\n",
        "                hidden = self.rnn_layers[t](input_seq[b][t], hidden)\n",
        "\n",
        "            # Store the last hidden state in the output tensor\n",
        "            last_hidden[b] = hidden\n",
        "\n",
        "        output = self.linear(last_hidden)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class PaddedModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, seq_len_max):\n",
        "        super(PaddedModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len_max = seq_len_max\n",
        "        self.rnn_layers = nn.ModuleList([RNNLayer(input_size, hidden_size) for _ in range(seq_len_max)])\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, padded_batch, lengths):\n",
        "        B, T, _ = padded_batch.shape\n",
        "        device = padded_batch.device\n",
        "\n",
        "        hidden = [torch.zeros(self.hidden_size, device=device) for _ in range(B)]\n",
        "\n",
        "        for t in range(T):\n",
        "            for b in range(B):\n",
        "                if t < lengths[b]:\n",
        "\n",
        "                    hidden[b] = self.rnn_layers[t](padded_batch[b, t], hidden[b])\n",
        "\n",
        "        last_hidden = torch.stack(hidden, dim=0)\n",
        "        return self.linear(last_hidden)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fedf63ec",
      "metadata": {
        "id": "fedf63ec"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters and other settings\n",
        "input_size = 10  # Replace with the actual dimension of your input features\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# load data\n",
        "X_train, X_test, y_train, y_test = loadData()\n",
        "device = y_train.device\n",
        "\n",
        "# Create the model using min length input\n",
        "seq_lengths = [seq.shape[0] for seq in X_train]\n",
        "\n",
        "\n",
        "all_indices = np.arange(len(X_train))\n",
        "np.random.shuffle(all_indices)\n",
        "\n",
        "train_cutoff = int(0.8 * len(all_indices))\n",
        "train_indices = all_indices[:train_cutoff]\n",
        "val_indices   = all_indices[train_cutoff:]\n",
        "\n",
        "\n",
        "X_train_split = []\n",
        "for i in train_indices:\n",
        "    X_train_split.append(X_train[i])\n",
        "y_train_split = y_train[train_indices]\n",
        "\n",
        "\n",
        "X_val_split = []\n",
        "for i in val_indices:\n",
        "    X_val_split.append(X_train[i])\n",
        "y_val_split = y_train[val_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cc48c214",
      "metadata": {
        "id": "cc48c214"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, num_epochs, lr, batch_size, X_train, y_train, seq_lengths):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    print(\"training!\")\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        print(\"epoch \", epoch)\n",
        "\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            inputs = X_train[i:i+batch_size]\n",
        "            targets = y_train[i:i+batch_size]\n",
        "            lengths = seq_lengths[i:i+batch_size]\n",
        "\n",
        "            #GPU related stuff to ensure it picks the right device\n",
        "            inputs  = [x.to(device) for x in inputs]\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, lengths)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        MSE_val = mse_padded(model, X_val_split, y_val_split)\n",
        "        print(\"MSE \", MSE_val)\n",
        "        print(loss)\n",
        "    return model\n",
        "\n",
        "def train_padded(model, num_epochs, lr, batch_size, X_train, y_train):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(\"training padded!\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"epoch \",epoch)\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch = X_train[i:i+batch_size]\n",
        "            targets = y_train[i:i+batch_size].to(device)\n",
        "\n",
        "            lengths = [len(s) for s in batch]\n",
        "            padded = pad_sequence(batch, batch_first=True).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(padded, lengths)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        MSE_val = mse_padded(model, X_val_split, y_val_split)\n",
        "        print(\"Padded MSE \", MSE_val)\n",
        "        print(loss.item())\n",
        "\n",
        "\n",
        "def mse(model, inputs, y):\n",
        "    model.eval()\n",
        "    crit = nn.MSELoss()\n",
        "    preds = []\n",
        "    bs = 64\n",
        "    lengths = []\n",
        "\n",
        "    for x in inputs:\n",
        "        lengths.append(len(x))\n",
        "\n",
        "    for i in range(0, len(inputs), bs):\n",
        "\n",
        "        batch = []\n",
        "        for x in inputs[i:i+bs]:\n",
        "            batch.append(x.to(device))\n",
        "\n",
        "        lens  = lengths[i:i+bs]\n",
        "        preds.append(model(batch, lens))\n",
        "\n",
        "    preds = torch.cat(preds, dim=0)\n",
        "\n",
        "    return crit(preds, y.to(device)).item()\n",
        "\n",
        "\n",
        "\n",
        "def mse_padded(model, inputs, y):\n",
        "    model.eval()\n",
        "    crit = nn.MSELoss()\n",
        "    preds = []\n",
        "    bs = 64\n",
        "\n",
        "    lengths = []\n",
        "    for x in inputs:\n",
        "        lengths.append(len(x))\n",
        "\n",
        "    for i in range(0, len(inputs), bs):\n",
        "        batch = []\n",
        "        for x in inputs[i:i+bs]:\n",
        "            batch.append(x.to(device))\n",
        "\n",
        "        lens = lengths[i:i+bs]\n",
        "        padded = pad_sequence(batch, batch_first=True)\n",
        "\n",
        "        preds.append(model(padded, lens))\n",
        "\n",
        "    preds = torch.cat(preds, dim=0)\n",
        "    return crit(preds, y.to(device)).item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "92cd8187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92cd8187",
        "outputId": "5dccbc55-fa86-4640-8f66-612b9bf59065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu selected. no visible gpu\n",
            "Vanilla RNN . . . . .\n",
            "training!\n",
            "epoch  0\n",
            "MSE  0.019275978207588196\n",
            "tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
            "epoch  1\n",
            "MSE  0.012702079489827156\n",
            "tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
            "epoch  2\n",
            "MSE  0.008365921676158905\n",
            "tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
            "epoch  3\n",
            "MSE  0.005394916981458664\n",
            "tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
            "epoch  4\n",
            "MSE  0.0033081411384046078\n",
            "tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
            "epoch  5\n",
            "MSE  0.0019416179275140166\n",
            "tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch  6\n",
            "MSE  0.0011280523613095284\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch  7\n",
            "MSE  0.0006615080637857318\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch  8\n",
            "MSE  0.00040001189336180687\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch  9\n",
            "MSE  0.0002588455390650779\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "fixed length truncated model....\n",
            "training!\n",
            "epoch  0\n",
            "MSE  0.01090302038937807\n",
            "tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
            "epoch  1\n",
            "MSE  0.009235186502337456\n",
            "tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
            "epoch  2\n",
            "MSE  0.008770066313445568\n",
            "tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
            "epoch  3\n",
            "MSE  0.008530529215931892\n",
            "tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
            "epoch  4\n",
            "MSE  0.008626209571957588\n",
            "tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
            "epoch  5\n",
            "MSE  0.008597632870078087\n",
            "tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
            "epoch  6\n",
            "MSE  0.008535130880773067\n",
            "tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
            "epoch  7\n",
            "MSE  0.008532710373401642\n",
            "tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
            "epoch  8\n",
            "MSE  0.00852106511592865\n",
            "tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "epoch  9\n",
            "MSE  0.008514193817973137\n",
            "tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "padded model ....\n",
            "training padded!\n",
            "epoch  0\n",
            "Padded MSE  0.023514097556471825\n",
            "0.034565091133117676\n",
            "epoch  1\n",
            "Padded MSE  0.012983511202037334\n",
            "0.017391806468367577\n",
            "epoch  2\n",
            "Padded MSE  0.008208412677049637\n",
            "0.01027042418718338\n",
            "epoch  3\n",
            "Padded MSE  0.005899517796933651\n",
            "0.006686745211482048\n",
            "epoch  4\n",
            "Padded MSE  0.004288738127797842\n",
            "0.0052238949574530125\n",
            "epoch  5\n",
            "Padded MSE  0.003118603490293026\n",
            "0.0042826831340789795\n",
            "epoch  6\n",
            "Padded MSE  0.002316394355148077\n",
            "0.0033069662749767303\n",
            "epoch  7\n",
            "Padded MSE  0.0016895529115572572\n",
            "0.0025147662963718176\n",
            "epoch  8\n",
            "Padded MSE  0.0012454017996788025\n",
            "0.0019126953557133675\n",
            "epoch  9\n",
            "Padded MSE  0.0009358171373605728\n",
            "0.001503477804362774\n",
            "testing each\n",
            "vanilla test!!   0.00036904800799675286 truncated test!!  0.009197115898132324 Padded Test!!  0.00724533898755908\n"
          ]
        }
      ],
      "source": [
        "#| label: prob2\n",
        "\n",
        "# initialize and train Vanilla RNN\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    X_train, X_test, y_train, y_test = loadData()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\") # pick my gpu\n",
        "        print(\"cuda selected!\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"cpu selected. no visible gpu\")\n",
        "\n",
        "\n",
        "\n",
        "    seq_lengths_tr  = [len(x) for x in X_train_split]\n",
        "    seq_lengths_val = [len(x) for x in X_val_split]\n",
        "\n",
        "    print(\"Vanilla RNN . . . . .\")\n",
        "    vanilla = SequenceModel(input_size, hidden_size, output_size).to(device)\n",
        "    train_vanilla_RNN =train(vanilla, num_epochs, learning_rate, batch_size, X_train, y_train, seq_lengths)\n",
        "\n",
        "\n",
        "    print (\"fixed length truncated model....\")\n",
        "\n",
        "\n",
        "    Lmin = min(seq_lengths)\n",
        "    X_train_trunc = []\n",
        "\n",
        "    for x in X_train:\n",
        "         truncated_seq = x[:Lmin]\n",
        "         X_train_trunc.append(truncated_seq)\n",
        "\n",
        "    seq_lengths_trunc = [Lmin] * len(X_train_trunc)\n",
        "\n",
        "\n",
        "    trunc = SequenceModelFixedLen(input_size, hidden_size, output_size, seq_len=Lmin).to(device)\n",
        "    Train_trunc = train(trunc, num_epochs, learning_rate, batch_size, X_train_trunc, y_train, seq_lengths_trunc)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"padded model ....\")\n",
        "    Lmax = max(seq_lengths)\n",
        "    padded_model = PaddedModel(input_size, hidden_size, output_size, seq_len_max=Lmax).to(device)\n",
        "    train_padded(padded_model, num_epochs, learning_rate, batch_size, X_train, y_train)\n",
        "\n",
        "\n",
        "    print(\"testing each\")\n",
        "    vanilla_test = mse(vanilla, X_test, y_test)\n",
        "\n",
        "    trunc_test = []\n",
        "\n",
        "    for x in X_test:\n",
        "        truncated_seq = x[:Lmin]\n",
        "        trunc_test.append(truncated_seq)\n",
        "\n",
        "    test_trunc   = mse(trunc, trunc_test, y_test)\n",
        "\n",
        "    padded_test  = mse_padded(padded_model, X_test, y_test)\n",
        "\n",
        "    print(\"vanilla test!!  \", vanilla_test , \"truncated test!! \" , test_trunc , \"Padded Test!! \", padded_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#| label: prob2v2\n",
        "\n",
        "print(\"vanilla test!!  \", vanilla_test , \"truncated test!! \" , test_trunc , \"Padded Test!! \", padded_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TldgJxep4eXE",
        "outputId": "f394b056-b316-44e8-8371-6fdeb2d705cb"
      },
      "id": "TldgJxep4eXE",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vanilla test!!   0.00036904800799675286 truncated test!!  0.009197115898132324 Padded Test!!  0.00724533898755908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5267b62c",
      "metadata": {
        "id": "5267b62c"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "# initialize and train Sequential NN fixing #timesteps to the minimum sequence length\n",
        "\n",
        "# initialize and train Sequential NN fixing #timesteps to the maximum sequence length\n",
        "# NOTE: it is OK to use torch.nn.utils.rnn.pad_sequence; make sure to set parameter batch_first correctly\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}