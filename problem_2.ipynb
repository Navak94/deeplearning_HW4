{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f30bcfa9",
      "metadata": {
        "id": "f30bcfa9",
        "outputId": "9684e012-d3d4-4322-d3e5-033f7cbd07f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "path = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2f1f70d6",
      "metadata": {
        "id": "2f1f70d6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "os.chdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "76f0ed51",
      "metadata": {
        "id": "76f0ed51"
      },
      "outputs": [],
      "source": [
        "# load training and test data\n",
        "def loadData():\n",
        "    X_train = np.load('X_train.npy',allow_pickle=True)\n",
        "    y_train = np.load('y_train.npy',allow_pickle=True)\n",
        "    X_test = np.load('X_test.npy',allow_pickle=True)\n",
        "    y_test = np.load('y_test.npy',allow_pickle=True)\n",
        "\n",
        "    X_train = [torch.Tensor(x) for x in X_train]  # List of Tensors (SEQ_LEN[i],INPUT_DIM) i=0..NUM_SAMPLES-1\n",
        "    X_test = [torch.Tensor(x) for x in X_test]  # List of Tensors (SEQ_LEN[i],INPUT_DIM)\n",
        "    y_train = torch.Tensor(y_train) # (NUM_SAMPLES,1)\n",
        "    y_test = torch.Tensor(y_test) # (NUM_SAMPLES,1)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "21bb0ab1",
      "metadata": {
        "id": "21bb0ab1"
      },
      "outputs": [],
      "source": [
        "# Define a Vanilla RNN layer by hand\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.W_xh = nn.Parameter(torch.randn(input_size, hidden_size) * 0.01)\n",
        "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "        self.activation = torch.tanh\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        hidden = self.activation(x @ self.W_xh + hidden @ self.W_hh)\n",
        "        return hidden\n",
        "\n",
        "# Define a sequence prediction model using the Vanilla RNN\n",
        "class SequenceModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SequenceModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = RNNLayer(input_size, hidden_size)\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq, seq_lengths):\n",
        "        batch_size = len(input_seq)\n",
        "        last_hidden = torch.zeros(batch_size, self.hidden_size, device=device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            hidden = torch.zeros(self.hidden_size, device=device)\n",
        "\n",
        "            seq_length =  seq_lengths[b]\n",
        "\n",
        "            for t in range(seq_length):\n",
        "                hidden = self.rnn(input_seq[b][t], hidden)\n",
        "\n",
        "            # Store the last hidden state in the output tensor\n",
        "            last_hidden[b] = hidden\n",
        "\n",
        "        output = self.linear(last_hidden)\n",
        "        return output\n",
        "\n",
        "# Define a sequence prediction model for fixed length sequences, BUT NO SHARED WEIGHTS\n",
        "class SequenceModelFixedLen(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, seq_len):\n",
        "        super(SequenceModelFixedLen, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.rnn_layers = nn.ModuleList([RNNLayer(input_size, hidden_size) for _ in range(seq_len)])\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq, seq_lengths):\n",
        "        batch_size = len(input_seq)\n",
        "        last_hidden = torch.zeros(batch_size, self.hidden_size, device=device)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            hidden = torch.zeros(self.hidden_size, device=device).to(device)\n",
        "\n",
        "            seq_length = min(self.seq_len, seq_lengths[b]) ######################################## I think???\n",
        "            for t in range(seq_length):\n",
        "                hidden = self.rnn_layers[t](input_seq[b][t], hidden)\n",
        "\n",
        "            # Store the last hidden state in the output tensor\n",
        "            last_hidden[b] = hidden\n",
        "\n",
        "        output = self.linear(last_hidden)\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class PaddedModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, seq_len_max):\n",
        "        super(PaddedModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len_max = seq_len_max\n",
        "        self.rnn_layers = nn.ModuleList([RNNLayer(input_size, hidden_size) for _ in range(seq_len_max)])\n",
        "        self.linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, padded_batch, lengths):\n",
        "        B, T, _ = padded_batch.shape\n",
        "        device = padded_batch.device\n",
        "\n",
        "        hidden = [torch.zeros(self.hidden_size, device=device) for _ in range(B)]\n",
        "\n",
        "        for t in range(T):\n",
        "            for b in range(B):\n",
        "                if t < lengths[b]:\n",
        "\n",
        "                    hidden[b] = self.rnn_layers[t](padded_batch[b, t], hidden[b])\n",
        "\n",
        "        last_hidden = torch.stack(hidden, dim=0)\n",
        "        return self.linear(last_hidden)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fedf63ec",
      "metadata": {
        "id": "fedf63ec"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters and other settings\n",
        "input_size = 10  # Replace with the actual dimension of your input features\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# load data\n",
        "X_train, X_test, y_train, y_test = loadData()\n",
        "device = y_train.device\n",
        "\n",
        "# Create the model using min length input\n",
        "seq_lengths = [seq.shape[0] for seq in X_train]\n",
        "\n",
        "\n",
        "all_indices = np.arange(len(X_train))\n",
        "np.random.shuffle(all_indices)\n",
        "\n",
        "train_cutoff = int(0.8 * len(all_indices))\n",
        "train_indices = all_indices[:train_cutoff]\n",
        "val_indices   = all_indices[train_cutoff:]\n",
        "\n",
        "\n",
        "X_train_split = []\n",
        "for i in train_indices:\n",
        "    X_train_split.append(X_train[i])\n",
        "y_train_split = y_train[train_indices]\n",
        "\n",
        "\n",
        "X_val_split = []\n",
        "for i in val_indices:\n",
        "    X_val_split.append(X_train[i])\n",
        "y_val_split = y_train[val_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cc48c214",
      "metadata": {
        "id": "cc48c214"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, num_epochs, lr, batch_size, X_train, y_train, seq_lengths):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    print(\"training!\")\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        print(\"epoch \", epoch)\n",
        "\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            inputs = X_train[i:i+batch_size]\n",
        "            targets = y_train[i:i+batch_size]\n",
        "            lengths = seq_lengths[i:i+batch_size]\n",
        "\n",
        "            #GPU related stuff to ensure it picks the right device\n",
        "            inputs  = [x.to(device) for x in inputs]\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, lengths)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        MSE_val = mse_padded(model, X_val_split, y_val_split)\n",
        "        print(\"MSE \", MSE_val)\n",
        "        print(loss)\n",
        "    return model\n",
        "\n",
        "def train_padded(model, num_epochs, lr, batch_size, X_train, y_train):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(\"training padded!\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"epoch \",epoch)\n",
        "        for i in range(0, len(X_train), batch_size):\n",
        "            batch = X_train[i:i+batch_size]\n",
        "            targets = y_train[i:i+batch_size].to(device)\n",
        "\n",
        "            lengths = [len(s) for s in batch]\n",
        "            padded = pad_sequence(batch, batch_first=True).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(padded, lengths)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        MSE_val = mse_padded(model, X_val_split, y_val_split)\n",
        "        print(\"Padded MSE \", MSE_val)\n",
        "        print(loss.item())\n",
        "\n",
        "##################################################3revise the MSE\n",
        "def mse(model, inputs, y):\n",
        "    model.eval()\n",
        "    crit = nn.MSELoss()\n",
        "    preds = []\n",
        "    bs = 64\n",
        "    lengths = []\n",
        "\n",
        "    for x in inputs:\n",
        "        lengths.append(len(x))\n",
        "\n",
        "    for i in range(0, len(inputs), bs):\n",
        "\n",
        "        batch = []\n",
        "        for x in inputs[i:i+bs]:\n",
        "            batch.append(x.to(device))\n",
        "\n",
        "        lens  = lengths[i:i+bs]\n",
        "        preds.append(model(batch, lens))\n",
        "\n",
        "    preds = torch.cat(preds, dim=0)\n",
        "\n",
        "    return crit(preds, y.to(device)).item()\n",
        "\n",
        "\n",
        "\n",
        "def mse_padded(model, inputs, y):\n",
        "    model.eval()\n",
        "    crit = nn.MSELoss()\n",
        "    preds = []\n",
        "    bs = 64\n",
        "\n",
        "    lengths = []\n",
        "    for x in inputs:\n",
        "        lengths.append(len(x))\n",
        "\n",
        "    for i in range(0, len(inputs), bs):\n",
        "        batch = []\n",
        "        for x in inputs[i:i+bs]:\n",
        "            batch.append(x.to(device))\n",
        "\n",
        "        lens = lengths[i:i+bs]\n",
        "        padded = pad_sequence(batch, batch_first=True)\n",
        "\n",
        "        preds.append(model(padded, lens))\n",
        "\n",
        "    preds = torch.cat(preds, dim=0)\n",
        "    return crit(preds, y.to(device)).item()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "92cd8187",
      "metadata": {
        "id": "92cd8187",
        "outputId": "39dc68c1-157b-49a6-8b14-e3cd6fa60682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu selected. no visible gpu\n",
            "Vanilla RNN . . . . .\n",
            "training!\n",
            "epoch  0\n",
            "MSE  0.019099462777376175\n",
            "tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
            "epoch  1\n",
            "MSE  0.013001225888729095\n",
            "tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
            "epoch  2\n",
            "MSE  0.008580727502703667\n",
            "tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
            "epoch  3\n",
            "MSE  0.005586786661297083\n",
            "tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
            "epoch  4\n",
            "MSE  0.0034230253659188747\n",
            "tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch  5\n",
            "MSE  0.002040478168055415\n",
            "tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch  6\n",
            "MSE  0.0012030372163280845\n",
            "tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch  7\n",
            "MSE  0.0007104680989868939\n",
            "tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch  8\n",
            "MSE  0.0004281130968593061\n",
            "tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch  9\n",
            "MSE  0.0002707783423829824\n",
            "tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "fixed length truncated model....\n",
            "training!\n",
            "epoch  0\n",
            "MSE  0.011432254686951637\n",
            "tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
            "epoch  1\n",
            "MSE  0.010226656682789326\n",
            "tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
            "epoch  2\n",
            "MSE  0.009985236451029778\n",
            "tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
            "epoch  3\n",
            "MSE  0.009917458519339561\n",
            "tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
            "epoch  4\n",
            "MSE  0.00991235114634037\n",
            "tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
            "epoch  5\n",
            "MSE  0.00989609956741333\n",
            "tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
            "epoch  6\n",
            "MSE  0.009857979603111744\n",
            "tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
            "epoch  7\n",
            "MSE  0.009840172715485096\n",
            "tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "epoch  8\n",
            "MSE  0.00985043030232191\n",
            "tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "epoch  9\n",
            "MSE  0.009852180257439613\n",
            "tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "padded model ....\n",
            "training padded!\n",
            "epoch  0\n",
            "Padded MSE  0.027117330580949783\n",
            "0.03524834290146828\n",
            "epoch  1\n",
            "Padded MSE  0.014750214293599129\n",
            "0.01739320531487465\n",
            "epoch  2\n",
            "Padded MSE  0.009837111458182335\n",
            "0.010536674410104752\n",
            "epoch  3\n",
            "Padded MSE  0.006703516002744436\n",
            "0.0069600315764546394\n",
            "epoch  4\n",
            "Padded MSE  0.004621483385562897\n",
            "0.0053862594068050385\n",
            "epoch  5\n",
            "Padded MSE  0.0032316737342625856\n",
            "0.004399637691676617\n",
            "epoch  6\n",
            "Padded MSE  0.0023119321558624506\n",
            "0.003377618733793497\n",
            "epoch  7\n",
            "Padded MSE  0.0016791870584711432\n",
            "0.002543291077017784\n",
            "epoch  8\n",
            "Padded MSE  0.0012447277549654245\n",
            "0.001959182322025299\n",
            "epoch  9\n",
            "Padded MSE  0.0009497213177382946\n",
            "0.0015704258112236857\n",
            "testing each\n",
            "vanilla test!!   0.0003656844492070377 truncated test!!  0.009216870181262493 Padded Test!!  0.0075728679075837135\n"
          ]
        }
      ],
      "source": [
        "# initialize and train Vanilla RNN\n",
        "if __name__ == \"__main__\":\n",
        "    ################################################################################################needs revision\n",
        "    X_train, X_test, y_train, y_test = loadData()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\") # pick my gpu\n",
        "        print(\"cuda selected!\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"cpu selected. no visible gpu\")\n",
        "\n",
        "\n",
        "\n",
        "    seq_lengths_tr  = [len(x) for x in X_train_split]\n",
        "    seq_lengths_val = [len(x) for x in X_val_split]\n",
        "\n",
        "    print(\"Vanilla RNN . . . . .\")\n",
        "    vanilla = SequenceModel(input_size, hidden_size, output_size).to(device)\n",
        "    train_vanilla_RNN =train(vanilla, num_epochs, learning_rate, batch_size, X_train, y_train, seq_lengths)\n",
        "\n",
        "\n",
        "    print (\"fixed length truncated model....\")\n",
        "\n",
        "\n",
        "    Lmin = min(seq_lengths)\n",
        "    X_train_trunc = []\n",
        "\n",
        "    for x in X_train:\n",
        "         truncated_seq = x[:Lmin]\n",
        "         X_train_trunc.append(truncated_seq)\n",
        "\n",
        "    seq_lengths_trunc = [Lmin] * len(X_train_trunc)\n",
        "\n",
        "\n",
        "    trunc = SequenceModelFixedLen(input_size, hidden_size, output_size, seq_len=Lmin).to(device)\n",
        "    Train_trunc = train(trunc, num_epochs, learning_rate, batch_size, X_train_trunc, y_train, seq_lengths_trunc)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"padded model ....\")\n",
        "    Lmax = max(seq_lengths)\n",
        "    padded_model = PaddedModel(input_size, hidden_size, output_size, seq_len_max=Lmax).to(device)\n",
        "    train_padded(padded_model, num_epochs, learning_rate, batch_size, X_train, y_train)\n",
        "\n",
        "\n",
        "    print(\"testing each\")\n",
        "    vanilla_test = mse(vanilla, X_test, y_test)\n",
        "\n",
        "    trunc_test = []\n",
        "\n",
        "    for x in X_test:\n",
        "        truncated_seq = x[:Lmin]\n",
        "        trunc_test.append(truncated_seq)\n",
        "\n",
        "    test_trunc   = mse(trunc, trunc_test, y_test)\n",
        "\n",
        "    padded_test  = mse_padded(padded_model, X_test, y_test)\n",
        "\n",
        "    print(\"vanilla test!!  \", vanilla_test , \"truncated test!! \" , test_trunc , \"Padded Test!! \", padded_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5267b62c",
      "metadata": {
        "id": "5267b62c"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################################################################################################################################\n",
        "\n",
        "# initialize and train Sequential NN fixing #timesteps to the minimum sequence length\n",
        "\n",
        "# initialize and train Sequential NN fixing #timesteps to the maximum sequence length\n",
        "# NOTE: it is OK to use torch.nn.utils.rnn.pad_sequence; make sure to set parameter batch_first correctly\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}