{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fq5qQL6nN4f"
      },
      "source": [
        "If you decide to participate in the competition, save the **predictions.json and flops_and_params.json** files in a zip folder with your group name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euVL16niu7I9"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j4LIaCuvJ-0",
        "outputId": "a6076fbb-4f11-4d48-d8d1-291f23bdea58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvIKvKL6Hc0i"
      },
      "outputs": [],
      "source": [
        "# unzip the files\n",
        "# to find the file path, right click the filename and select copy path\n",
        "# make sure don't change any file and folder name in the train_set and test_set\n",
        "# !unzip /content/test_set.zip\n",
        "# !unzip /content/train_set.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Hj7Gz7BJJn",
        "outputId": "61391450-0c6d-46a5-f82f-317c17ec9f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "# A simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self, num_classes=5):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(2048, 512)\n",
        "    self.fc2 = nn.Linear(512, 10)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(torch.relu(self.conv1(x)))\n",
        "    x = self.pool(torch.relu(self.conv2(x)))\n",
        "    x = self.pool(torch.relu(self.conv3(x)))\n",
        "    x = x.view(-1, 2048)\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "import torch.nn as nn\n",
        "\n",
        "class betterCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(betterCNN, self).__init__()\n",
        "        \n",
        "        # convolutional block\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # convolutional block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        # convolutional block\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        # pooling and dropout\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1 block\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # 2 block\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # 3 block\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(-1, 256 * 4 * 4)\n",
        "        \n",
        "        # fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = betterCNN(num_classes=5)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg9Ubr7iCj3y"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# augmentation method can be added in training\n",
        "# keep validation clean\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset_dir = '/content/train_set'\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=dataset_dir, transform=train_transform)\n",
        "# you may desgin your validation set, and change the value of the \"root\" parameter.\n",
        "val_dataset = datasets.ImageFolder(root=dataset_dir, transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# training transform with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# val transform (still without augmentation as in sample)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset_dir = '/content/train_set'\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=dataset_dir, transform=None)\n",
        "\n",
        "# train/val split sizes\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "#print(f\"Total images: {total_size}\")\n",
        "#print(f\"Training images: {train_size}\")\n",
        "#print(f\"Validation images: {val_size}\")\n",
        "\n",
        "# split into train/val indices\n",
        "train_indices = list(range(0, train_size))\n",
        "val_indices = list(range(train_size, total_size))\n",
        "\n",
        "# train dataset w augmentation\n",
        "train_dataset = datasets.ImageFolder(root=dataset_dir, transform=train_transform)\n",
        "train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "\n",
        "# val dataset w/o augmentation\n",
        "val_dataset = datasets.ImageFolder(root=dataset_dir, transform=val_transform)\n",
        "val_subset = torch.utils.data.Subset(val_dataset, val_indices)\n",
        "\n",
        "# data loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNJ-kQzPDL4a"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # loss + add label smoothing\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001) # optimizer + add weight decay\n",
        "# added learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=3,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdehV8l9DfZm",
        "outputId": "069a0bd4-bf56-4439-c52d-f0c07292cd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.5363955263580595\n",
            "Epoch 2, Loss: 1.4096388476235526\n",
            "Epoch 3, Loss: 1.2820373880011695\n",
            "Epoch 4, Loss: 1.150046474167279\n",
            "Epoch 5, Loss: 1.1198387209858214\n"
          ]
        }
      ],
      "source": [
        "def train(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # you may consider to\n",
        "        # save training log\n",
        "        # save model checkpoints\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
        "train(model, train_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=30):\n",
        "    best_val_acc = 0.0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 10\n",
        "    \n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # train\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        \n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss = running_loss + loss.item()\n",
        "            \n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            train_total = train_total + labels.size(0)\n",
        "            train_correct = train_correct + (predictions == labels).sum().item()\n",
        "        \n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100.0 * train_correct / train_total\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        # val\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                predictions = torch.max(outputs, 1)[1]\n",
        "                val_total = val_total + labels.size(0)\n",
        "                val_correct = val_correct + (predictions == labels).sum().item()\n",
        "        \n",
        "        val_acc = 100.0 * val_correct / val_total\n",
        "        val_accuracies.append(val_acc)\n",
        "        \n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(f\" -> Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\" -> Val Acc: {val_acc:.2f}%\")\n",
        "        \n",
        "        # new scheduler step\n",
        "        scheduler.step(val_acc)\n",
        "        \n",
        "        # save state added\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"----> Best model saved ---> Val Acc: {val_acc:.2f}%\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter = patience_counter + 1\n",
        "        \n",
        "        # early stopping\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            break\n",
        "        \n",
        "        print()\n",
        "    \n",
        "    return train_losses, val_accuracies\n",
        "\n",
        "train_losses, val_accuracies = train(\n",
        "    model, \n",
        "    train_loader, \n",
        "    val_loader, \n",
        "    criterion, \n",
        "    optimizer, \n",
        "    scheduler, \n",
        "    num_epochs=30\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruRHEnp1IoRV",
        "outputId": "59fcc6e7-375a-4dc5-a8e8-d8c35b948fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 57.42686736722522%\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * correct / total}%')\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW TOM + NATE BLOCK\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            predictions = torch.max(outputs, 1)[1]\n",
        "            total = total + labels.size(0)\n",
        "            correct = correct + (predictions == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100.0 * correct / total\n",
        "    print(f'Val Accuracy: {accuracy:.2f}%')\n",
        "    return accuracy\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "evaluate(model, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdi-7Yopl4dp"
      },
      "source": [
        "Please don't make any change after this line. The only parameters you may modify are those within the \"test_transform\" function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdVw9_b0I1ab"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def filename2index(self, filename):\n",
        "        return os.path.basename(filename).replace('.jpg', '')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.filename2index(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQZczVOMULb"
      },
      "outputs": [],
      "source": [
        "# if you save your model in advance, you can load it here.\n",
        "# model.load_state_dict(torch.load('your_trained_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxPmHc1OMa_8"
      },
      "outputs": [],
      "source": [
        "test_folder = './test_set'\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)), # same image size applied for validation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # same mean and std applied for validation\n",
        "])\n",
        "test_dataset = CustomImageDataset(test_folder, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "class_to_idx = train_dataset.class_to_idx\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jCDIWpGM0y-",
        "outputId": "2744a137-501b-4b9d-92cd-9aec6c78bbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation completed and predictions saved.\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "def evaluate_model(model, test_loader, idx_to_class):\n",
        "    all_predictions = {}\n",
        "    with torch.no_grad():\n",
        "        for inputs, index in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_class = predicted.item()\n",
        "            predicted_class_name = idx_to_class[predicted_class]\n",
        "            all_predictions[index[0]] = predicted_class_name\n",
        "\n",
        "    return all_predictions\n",
        "\n",
        "predictions = evaluate_model(model, test_loader, idx_to_class)\n",
        "with open('predictions.json', 'w') as json_file:\n",
        "    json.dump(predictions, json_file, indent=4)\n",
        "\n",
        "print(\"Evaluation completed and predictions saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ym3lmK2Eh36"
      },
      "outputs": [],
      "source": [
        "# you may need to install thop when you first run this code\n",
        "# !pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BecI85f3EYiA",
        "outputId": "534a08a5-ab62-4db5-eb46-d9f20585a1b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
            "FLOPs: 22751232.0\n",
            "Number of Parameters: 1147466.0\n",
            "FLOPs and parameters have been saved to flops_and_params.json\n"
          ]
        }
      ],
      "source": [
        "# Compute FLOPs using thop\n",
        "import thop\n",
        "input_tensor = test_dataset[0][0].unsqueeze(0) # must have exact same size of the data input (batch, channel, height, width)\n",
        "flops, params = thop.profile(model, inputs=(input_tensor,))\n",
        "print(f\"FLOPs: {flops}\")\n",
        "print(f\"Number of Parameters: {params}\")\n",
        "flops_and_params = {\n",
        "    \"FLOPs\": flops,\n",
        "    \"Parameters\": params\n",
        "}\n",
        "\n",
        "output_json_path = 'flops_and_params.json'\n",
        "\n",
        "with open(output_json_path, 'w') as json_file:\n",
        "    json.dump(flops_and_params, json_file, indent=4)\n",
        "\n",
        "print(f\"FLOPs and parameters have been saved to {output_json_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
